{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "! make clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "! make clean-logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm  -rf /media/sayem/510B93E12554BBD1/Hangman/wandb\n",
    "! rm -rf /media/sayem/510B93E12554BBD1/checkpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    random.seed(seed)       # Python random module\n",
    "    np.random.seed(seed)    # Numpy module\n",
    "    torch.manual_seed(seed) # PyTorch\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)          # Sets seed for CUDA (GPU)\n",
    "        torch.cuda.manual_seed_all(seed)      # Ensure reproducibility on all GPUs\n",
    "        torch.backends.cudnn.deterministic = True  # Use deterministic algorithms\n",
    "        torch.backends.cudnn.benchmark = False     # If input sizes do not vary, this should be set to False\n",
    "\n",
    "# Example usage: \n",
    "set_seed(42)  # Use any number to seed all libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# from src.datamodule import HangmanDataset\n",
    "from src.datamodule import HangmanDataModule\n",
    "# from src.datamodule import encode_and_pad_hangman_features\n",
    "# from src.datamodule import *\n",
    "# from src.model.neural_nets import *\n",
    "# from src.model.neural_nets.classifier import *\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "import lightning as L \n",
    "# # L.seed_everything(102, workers=True)\n",
    "# np.random.seed(102)  # You can use any number here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cuda.matmul.allow_tf32 = False\n",
    "# # torch.use_deterministic_algorithms(True)  # Requires PyTorch >= 1.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import read_word_list\n",
    "corpus_path = '/media/sayem/510B93E12554BBD1/Hangman/data/words_250000_train.txt'\n",
    "corpus = read_word_list(corpus_path, num_samples=250_000)  # corrected format for num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.utils import read_word_list\n",
    "\n",
    "NUM_STRATIFIED_SAMPLES = 250_000\n",
    "word_list_path = '/media/sayem/510B93E12554BBD1/Hangman/notebooks/api_key.txt'\n",
    "word_list = read_word_list(word_list_path, num_samples=NUM_STRATIFIED_SAMPLES)\n",
    "\n",
    "# Base dataset directory and subdirectories\n",
    "base_dataset_dir = Path(\"/media/sayem/510B93E12554BBD1/dataset/\")\n",
    "# parquet_path = base_dataset_dir / str(NUM_STRATIFIED_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = -[w_i * (y_i * pos_weight * log(sigma(x_i)) + (1 - y_i) * log(1 - sigma(x_i)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_params = {\n",
    "    \"vocab_size\": 28,               # Non-tunable: Set based on the dataset specifics (number of unique characters)\n",
    "    \"embedding_dim\": 50,           # Tunable: Size of the embedding vectors\n",
    "    \"hidden_dim\": 128,              # Tunable: Hidden layer size in LSTM\n",
    "    \"num_layers\": 5,                # Tunable: Number of layers in the LSTM\n",
    "    \"bidirectional\": True,          # Tunable: Whether the LSTM is bidirectional\n",
    "    \"dropout\": 0.3,                 # Tunable: Dropout rate to prevent overfitting\n",
    "    \"max_norm\": 1,                  # Tunable: Maximum norm for gradient clipping\n",
    "    \"feature_dim\": 5                # Non-tunable/Tunable: Depending on whether \n",
    "                                    # this is a fixed architectural choice or could be optimized\n",
    "}\n",
    "\n",
    "# # Assuming the EmbeddingLSTM class is defined somewhere and imported\n",
    "# # Instantiate the feature extractor with parameters unpacked from the dictionary\n",
    "# feature_extractor = EmbeddingLSTM(**feature_extractor_params)\n",
    "\n",
    "# Assuming `feature_extractor_params` has keys 'hidden_dim' and 'bidirectional'\n",
    "input_dim = feature_extractor_params['hidden_dim'] * 2 if \\\n",
    "    feature_extractor_params.get('bidirectional', False) else feature_extractor_params['hidden_dim']\n",
    "\n",
    "classifier_params = {\n",
    "    \"input_dim\": input_dim,         # Non-tunable: Computed based on 'hidden_dim' from LSTM and whether it is bidirectional\n",
    "    \"output_dims\": 26,              # Non-tunable: Set based on the number of labels (assumes fixed number of classes)\n",
    "    \"initial_biases\": None,  # Tunable: Could be optimized if linked to class imbalance\n",
    "    \"hidden_dims\": [256, 128, 64],   # Tunable: Sizes of additional hidden layers in the classifier\n",
    "    \"dropout\": 0.3,                 # Tunable: Dropout rate for regularization\n",
    "    \"norm_layer_func\": torch.nn.LayerNorm,  # Tunable: Type of normalization layer can affect model performance\n",
    "    \"activation_layer\": torch.nn.ReLU,  # Tunable: Choice of activation function can influence model dynamics\n",
    "    # \"randomize\": True              # Non-tunable/Tunable: Typically a methodological choice, not a hyperparameter\n",
    "}\n",
    "\n",
    "# # Initialize the classifier with parameters unpacked from the dictionary\n",
    "# classifier = DynamicClassifierChain(**classifier_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "# Example optimizer and scheduler configuration\n",
    "optimizer_config = {\n",
    "    'type': Adam,\n",
    "    'params': {'lr': 0.001, 'betas': (0.9, 0.999)}\n",
    "}\n",
    "\n",
    "# from torch.optim import SGD\n",
    "\n",
    "# # Example optimizer configuration using SGD\n",
    "# optimizer_config = {\n",
    "#     'type': SGD,\n",
    "#     'params': {'lr': 0.01, 'momentum': 0.9}\n",
    "# }\n",
    "\n",
    "scheduler_config = {\n",
    "    'type': ReduceLROnPlateau,\n",
    "    'params': {\n",
    "        'mode': 'max',  # or 'min' depending on the nature of the metric to monitor\n",
    "        'factor': 0.1,  # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "        'patience': 10,  # Number of epochs with no improvement after which learning rate will be reduced.\n",
    "        'threshold': 0.01,  # Minimal change to qualify as an improvement.\n",
    "        'threshold_mode': 'rel',  # 'rel' implies relative change, 'abs' implies absolute change.\n",
    "        'cooldown': 0,  # Number of epochs to wait before resuming normal operation after lr has been reduced.\n",
    "        'min_lr': 0,  # A lower bound on the learning rate of all param groups or each group respectively.\n",
    "        'eps': 1e-08,  # Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored.\n",
    "        # 'verbose': True  # If True, prints a message to stdout for each update.\n",
    "    },\n",
    "    'interval': 'epoch',  # 'ReduceLROnPlateau' typically does not need the 'interval' and 'frequency' since it works based on metric change.\n",
    "    'frequency': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import HangmanModel\n",
    "from src.model.components import EmbeddingLSTM, LabelEmbeddingNN, BinaryRelevanceClassifier\n",
    "from src.data_generation.strategy import HangmanFreqSolver # strategy\n",
    "# from src.model.components import GuessAccuracy\n",
    "from pytorchltr.loss import PairwiseHingeLoss, LambdaARPLoss1, \\\n",
    "    LambdaARPLoss2, LambdaNDCGLoss2, PairwiseDCGHingeLoss, PairwiseLogisticLoss\n",
    "\n",
    "solver = HangmanFreqSolver(corpus)\n",
    "# metric = GuessAccuracy(solver=solver)\n",
    "criterion = PairwiseLogisticLoss(sigma=1.0)\n",
    "# criterion = PairwiseHingeLoss() # thresholds = torch.full((26,), 0.5)\n",
    "# print(thresholds)\n",
    "model = HangmanModel(\n",
    "                     feature_extractor=EmbeddingLSTM, \n",
    "                     feature_extractor_params=feature_extractor_params,\n",
    "                     classifier=BinaryRelevanceClassifier, #LabelEmbeddingNN,\n",
    "                     classifier_params=classifier_params,\n",
    "                     optimizer_config=optimizer_config,\n",
    "                     scheduler_config=scheduler_config,\n",
    "                     pos_weight = None\n",
    "                    #  critarion=criterion\n",
    ")\n",
    "# model = model.to('cuda')\n",
    "# model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (train_dataset, val_dataset) in enumerate(fold_datasets):\n",
    "#     train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True, \n",
    "#                                   num_workers=os.cpu_count(), collate_fn=datamodule.collate_fn)\n",
    "\n",
    "#     val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, \n",
    "#                                 num_workers=os.cpu_count(), collate_fn=datamodule.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = 'checkpoints/best-checkpoint.ckpt'\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "# hyper_parameters = checkpoint[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper_parameters = checkpoint[\"hyper_parameters\"]\n",
    "# # if you want to restore any hyperparameters, you can pass them too\n",
    "# # model = HangmanModel(critarion=criterion, **hyper_parameters)\n",
    "# model = HangmanModel(**hyper_parameters)\n",
    "# model_weights = checkpoint[\"state_dict\"]\n",
    "# model.load_state_dict(model_weights)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cpu')\n",
    "# trainer.validate(model, datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generating action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generation.simulation import play_a_game_with_a_word, \\\n",
    "    simulate_games_for_word_list # testing function\n",
    "from src.datamodule.transforms import ProcessWordTransform\n",
    "from src.data_generation.strategy import HangmanFreqSolver # strategy\n",
    "from src.data_generation.process_word import process_word\n",
    "from src.datamodule.dataset import encode_character\n",
    "\n",
    "from src.model.inference import guess, guess_character\n",
    "from src.datamodule.transforms import ProcessWordTransform\n",
    "# from src.model.strategy import HangmanFreqSolver # strategy\n",
    "from src.data_generation.simulation import play_a_game_with_a_word, \\\n",
    "                            simulate_games_for_word_list # testing function\n",
    "from src.data_generation.data_generation \\\n",
    "    import simulated_guess_function, generate_a_game_with_a_word\n",
    "\n",
    "solver = HangmanFreqSolver(corpus) # TODO: does it matter waht corpus, since no use use in guess?\n",
    "transform = ProcessWordTransform(corpus) # here, what corpus does not matter\n",
    "\n",
    "# Example word\n",
    "# # real_word = 'aaup' \n",
    "# word = 'mississippi' # out of corpus\n",
    "# word = 'zyg' # from corpus\n",
    "word = 'microspace'\n",
    "# # real_word = 'ask'\n",
    "# masked_word = \"_\" * len(real_word)\n",
    "# # masked_word = \"aa__\"\n",
    "# guessed_letters = []\n",
    "# word = 'apple'\n",
    "masked_word = '_' * len(word)\n",
    "guessed_letters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = 'min'\n",
    "\n",
    "# simulated_guess_function(word, masked_word, \\\n",
    "#             solver, guessed_letters, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = 'min'\n",
    "# # from src.data_generation.data_generation import simulated_guess_function # same as guess+ guess character function\n",
    "# generate_a_game_with_a_word(word=word, \\\n",
    "#             guess_function=simulated_guess_function, \\\n",
    "#             solver=solver, strategy=strategy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = 'max'\n",
    "# # from src.data_generation.data_generation import simulated_guess_function # same as guess+ guess character function\n",
    "# # generate_a_game_with_a_word(word=word, \\\n",
    "#         guess_function=simulated_guess_function, \\\n",
    "#         solver=solver, strategy=strategy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = 'random'\n",
    "# # from src.data_generation.data_generation import simulated_guess_function # same as guess+ guess character function\n",
    "# generate_a_game_with_a_word(word=word, \\\n",
    "#         guess_function=simulated_guess_function, \\\n",
    "#         solver=solver, strategy=strategy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy = 'random_420'\n",
    "# # from src.data_generation.data_generation import simulated_guess_function # same as guess+ guess character function\n",
    "# generate_a_game_with_a_word(word=word, \\\n",
    "#         guess_function=simulated_guess_function, \\\n",
    "#         solver=solver, strategy=strategy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.data_generation.data_generation import simulated_guess_function, generate_a_game_with_a_word\n",
    "# # model = model.to('cuda')\n",
    "# # # Example usage\n",
    "# # solver = HangmanFreqSolver(corpus)\n",
    "# corpus_path_ = 'data/20k.txt'\n",
    "# word_list = read_word_list(corpus_path_, num_samples=1_000)\n",
    "# final_results = simulate_games_for_word_list(word_list=word_list, guess_function=simulated_guess_function, \\\n",
    "#                                             play_function=generate_a_game_with_a_word, \\\n",
    "#                                             model=None, solver=solver, \\\n",
    "#                                             transform=transform, process_word_fn=process_word) \n",
    "\n",
    "# # Print overall statistics\n",
    "# overall_stats = final_results['overall']\n",
    "# print(\"\\nOverall Statistics:\")\n",
    "# print(f\"Total Games: {overall_stats['total_games']}, Wins: {overall_stats['wins']}, Losses: {overall_stats['losses']}\")\n",
    "# print(f\"Win Rate: {overall_stats['win_rate']:.2f}, Average_tries_remaining: {overall_stats['average_tries_remaining']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Motoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.inference import guess, guess_character\n",
    "from src.datamodule.transforms import ProcessWordTransform\n",
    "# from src.model.strategy import HangmanFreqSolver # strategy\n",
    "from src.data_generation.simulation import play_a_game_with_a_word, \\\n",
    "                            simulate_games_for_word_list # testing function\n",
    "\n",
    "result = process_word(word, transform)\n",
    "print(result)\n",
    "real_word = 'aarau'\n",
    "# real_word = 'mississippi' # out of corpus\n",
    "# real_word = 'zyg' # from corpus\"\n",
    "# real_word = 'ask'\n",
    "masked_word = \"_\" * len(real_word)\n",
    "# masked_word = \"aa__\"\n",
    "guessed_letters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess(model=model, word=masked_word, # TODO\n",
    "    solver=solver, \\\n",
    "    guessed_letters=guessed_letters, \n",
    "    transform=transform,\n",
    "    process_word_fn=process_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.env import HangmanEnv\n",
    "\n",
    "# Usage Example\n",
    "# if __name__ == \"__main__\":\n",
    "# words = [\"python\", \"algorithm\", \"function\", \"variable\"]\n",
    "env = HangmanEnv(\"example\")\n",
    "print(\"Initial state:\", env.reset())\n",
    "# print()\n",
    "# action = 'e'  # Guessing 'e'\n",
    "# observation, reward, done = env.step(action)\n",
    "# print(\"Observation:\", observation)\n",
    "# print(\"Reward:\", reward)\n",
    "# print(\"Done:\", done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks, is_masking_supported\n",
    "\n",
    "# action_masks = get_action_masks(vec_env)\n",
    "is_masking_supported(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_action_masks(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env = HangmanEnv(\"ant\")\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        print('Observation:', observation)\n",
    "        action = env.action_space.sample()\n",
    "        # print(action)\n",
    "\n",
    "        action_mask = get_action_masks(env)\n",
    "        print(f\"What can predict:\", action_mask)\n",
    "        \n",
    "        # guessed_letters = observation['guessed_letters']\n",
    "        # # print(guessed_letters)\n",
    "        # # # Convert action to corresponding letter and check if it has been guessed\n",
    "        while not action_mask[action]:  # Check if the action index (converted to a letter) is already guessed\n",
    "            print(f\"resampling\")\n",
    "            action = env.action_space.sample()  # Keep sampling until a new letter is found\n",
    "\n",
    "        print('Action: ', action)\n",
    "        # Perform the action in the environment\n",
    "        next_observation, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        print('Reward:', reward)\n",
    "        print('Next observation:', next_observation)\n",
    "        print('info:', info)\n",
    "        print('done:', done)\n",
    "        print()\n",
    "\n",
    "        # Update the initial observation for the next loop iteration\n",
    "        observation = next_observation\n",
    "        # break\n",
    "\n",
    "        # Optionally, env.render() if implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(word, **kwargs):\n",
    "    \"\"\" Returns a function that will initialize the Hangman environment with given parameters \"\"\"\n",
    "    def _init():\n",
    "        return HangmanEnv(word=word, **kwargs)\n",
    "    return _init\n",
    "\n",
    "\n",
    "words = [\"apple\", \"ant\", \"zgy\"]\n",
    "env_functions = [env_creator(word) for word in words]\n",
    "\n",
    "# # Using DummyVecEnv for simplicity and synchronicity\n",
    "vec_env = DummyVecEnv(env_fns=env_functions)\n",
    "# Using DummyVecEnv for simplicity and synchronicity\n",
    "# vec_env = SubprocVecEnv(env_fns=env_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.utils import get_action_masks, is_masking_supported\n",
    "\n",
    "# action_masks = get_action_masks(vec_env)\n",
    "is_masking_supported(vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_action_masks(vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.reset()\n",
    "actions = [vec_env.action_space.sample() for _ in range(len(words))]  # Ensure an action is sampled for each environment\n",
    "print(actions)\n",
    "vec_env.step(actions)  # Apply batch of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.num_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.policies import MaskableMultiInputActorCriticPolicy\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "model = MaskablePPO(MaskableMultiInputActorCriticPolicy, vec_env, verbose=1)\n",
    "model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# def make_env(word):\n",
    "#     def _init():\n",
    "#         return HangmanEnv(word=word)\n",
    "#     return _init\n",
    "\n",
    "def env_creator(word, **kwargs):\n",
    "    \"\"\" Returns a function that will initialize the Hangman environment with given parameters \"\"\"\n",
    "    def _init():\n",
    "        return HangmanEnv(word=word, **kwargs)\n",
    "    return _init\n",
    "\n",
    "\n",
    "# # words = [\"apple\", \"ant\", \"zgy\"]\n",
    "# env_functions = [env_creator(word) for word in words]\n",
    "\n",
    "\n",
    "# # # Batch processing and training\n",
    "# corpus = [\"word\", \"word\", \"word\"] # , ..., \"word250000\"]  # Actual list of words\n",
    "batch_size = 4  # Words per batch\n",
    "model = MaskablePPO(MaskableMultiInputActorCriticPolicy, \\\n",
    "            make_vec_env(lambda: HangmanEnv(\"placeholder\"), n_envs=batch_size), verbose=1)\n",
    "\n",
    "for i in range(0, len(corpus), batch_size):\n",
    "    batch_words = corpus[i:i + batch_size]\n",
    "    # print(len(batch_words))\n",
    "    env_fns = [env_creator(word) for word in batch_words]\n",
    "    # # vec_env = DummyVecEnv(env_fns)  # Create vectorized environment for the batch\n",
    "    vec_env = SubprocVecEnv(env_fns)\n",
    "    model.set_env(vec_env)  # Set the new environment to the model\n",
    "    model.learn(total_timesteps=10_000)  # Learning on the batch for a fixed number of timesteps\n",
    "\n",
    "    # # # Optionally, evaluate the model's performance on the batch\n",
    "    # # eval_callback = EvalCallback(vec_env, best_model_save_path='./logs/',\n",
    "    # #                              log_path='./logs/', eval_freq=500,\n",
    "    # #                              deterministic=True, render=False)\n",
    "    # # model.learn(total_timesteps=10000, callback=eval_callback)\n",
    "\n",
    "    vec_env.close()  # Close the environment after training on the batch\n",
    "    \n",
    "    if i + batch_size >= len(corpus):  # Check if this is the last batch\n",
    "        print(\"Last batch processed. Exiting loop.\")\n",
    "        break  # Exit the loop after the last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations = vec_env.reset()\n",
    "\n",
    "# dones = np.zeros(len(words), dtype=bool)\n",
    "# max_timesteps = 30\n",
    "# timestep = 0\n",
    "\n",
    "# while timestep < max_timesteps:\n",
    "#     print(f'Timestep {timestep + 1}:')\n",
    "#     print('Observations:', observations)\n",
    "    \n",
    "#     actions = []\n",
    "#     active_envs = 0  # Count active environments for this pass\n",
    "\n",
    "#     for i in range(len(words)):\n",
    "#         action = vec_env.action_space.sample()  # Randomly sample an action\n",
    "#         while observations['guessed_letters'][i][action] == 1:\n",
    "#             action = vec_env.action_space.sample()  # Ensure this action hasn't been taken before\n",
    "#         observations['guessed_letters'][i][action] = 1  # Mark the action as taken\n",
    "#         actions.append(action)\n",
    "#         active_envs += 1  # Count this as an active interaction\n",
    "\n",
    "#     print('Actions:', [chr(action + ord('a')) for action in actions])\n",
    "#     observations, rewards, dones, info = vec_env.step(actions)  # Apply batch of actions\n",
    "\n",
    "#     print('Rewards:', rewards)\n",
    "#     print('Infos:', info)\n",
    "#     print()\n",
    "\n",
    "#     timestep += active_envs  # Increment the timestep by the number of active environments\n",
    "\n",
    "#     # if all(dones):\n",
    "#     #     print('All games completed.')\n",
    "#     #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations = vec_env.reset()\n",
    "\n",
    "# # Loop through the environments\n",
    "# while True:\n",
    "#     actions = [vec_env.action_space.sample() for _ in range(len(words))]  # Ensure an action is sampled for each environment\n",
    "#     print(actions)\n",
    "#     observations, rewards, dones, truncated = vec_env.step(actions)  # Apply batch of actions\n",
    "    \n",
    "#     print('Actions:', [chr(action + ord('a')) for action in actions])\n",
    "#     print('Observations:', observations)\n",
    "#     print('Rewards:', rewards)\n",
    "#     print()\n",
    "    \n",
    "#     if all(dones):\n",
    "#         print('Game Over for all environments')\n",
    "#         break\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.optimal_threshold = torch.full((26,), 0.9) # thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_a_game_with_a_word(word=real_word, guess_function=guess, \\\n",
    "                model=model, solver=solver, transform=transform, \\\n",
    "                process_word_fn=process_word) # aggregated_data=None): # TODO: aggregated_data=None: remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_a_game_with_a_word(word=real_word, guess_function=guess, \\\n",
    "                model=model, solver=solver, transform=transform, \\\n",
    "                process_word_fn=process_word) # aggregated_data=None): # TODO: aggregated_data=None: remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.hparams['thresholds'] = torch.full((26,), 1) #datamodule.base_rate #torch.full((26,), 0.1) # thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cuda')\n",
    "# # # Example usage\n",
    "# # solver = HangmanFreqSolver(corpus)\n",
    "# corpus_path_ = '/media/sayem/510B93E12554BBD1/Hangman/data/20k.txt'\n",
    "\n",
    "# word_list = read_word_list(corpus_path_, num_samples=1_000)\n",
    "# final_results = simulate_games_for_word_list(word_list=word_list, guess_function=guess, \\\n",
    "#                                             play_function=play_a_game_with_a_word, \\\n",
    "#                                             model=model, solver=solver, \\\n",
    "#                                             transform=transform, process_word_fn=process_word) \n",
    "\n",
    "# # Print overall statistics\n",
    "# overall_stats = final_results['overall']\n",
    "# print(\"\\nOverall Statistics:\")\n",
    "# print(f\"Total Games: {overall_stats['total_games']}, Wins: {overall_stats['wins']}, Losses: {overall_stats['losses']}\")\n",
    "# print(f\"Win Rate: {overall_stats['win_rate']:.2f}, Average_tries_remaining: {overall_stats['average_tries_remaining']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to('cuda')\n",
    "# # # Example usage\n",
    "# # solver = HangmanFreqSolver(corpus)\n",
    "# corpus_path_ = 'data/20k.txt'\n",
    "# word_list = read_word_list(corpus_path_, num_samples=1_0)\n",
    "# final_results = simulate_games_for_word_list(word_list=word_list, guess_function=guess, \\\n",
    "#                                             play_function=play_a_game_with_a_word, \\\n",
    "#                                             model=model, solver=solver, \\\n",
    "#                                             transform=transform, process_word_fn=process_word, guessing_order=None) \n",
    "\n",
    "# # Print overall statistics\n",
    "# overall_stats = final_results['overall']\n",
    "# avg_tries_remaining = overall_stats['average_tries_remaining']\n",
    "# print(avg_tries_remaining)\n",
    "# print(\"\\nOverall Statistics:\")\n",
    "# print(f\"Total Games: {overall_stats['total_games']}, Wins: {overall_stats['wins']}, Losses: {overall_stats['losses']}\")\n",
    "# print(f\"Win Rate: {overall_stats['win_rate']:.2f}, Average_tries_remaining: {overall_stats['average_tries_remaining']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# def multi_objective_trial(trial):\n",
    "#     # Define the range for each threshold as a trial suggestion\n",
    "#     thresholds = [trial.suggest_float(f'threshold_{i}', 0, 1) for i in range(26)]\n",
    "#     thresholds_tensor = torch.tensor(thresholds, dtype=torch.float, device='cuda')\n",
    "#     model.hparams['thresholds'] = thresholds_tensor\n",
    "#     corpus_path_ = 'data/20k.txt'\n",
    "#     word_list = read_word_list(corpus_path_, num_samples=1_000)\n",
    "        \n",
    "#     # Run the game simulation\n",
    "#     final_results = simulate_games_for_word_list(word_list=word_list, guess_function=guess, \n",
    "#                                                  play_function=play_a_game_with_a_word, \n",
    "#                                                  model=model, solver=solver, \n",
    "#                                                  transform=transform, process_word_fn=process_word)\n",
    "    \n",
    "#     # Return multiple objectives: win rate and negative average tries remaining (to maximize)\n",
    "#     win_rate = final_results['overall']['win_rate']\n",
    "#     avg_tries_remaining = final_results['overall']['average_tries_remaining']\n",
    "#     return win_rate, avg_tries_remaining\n",
    "\n",
    "# # def main():\n",
    "# # Create a multi-objective study\n",
    "# study = optuna.create_study(directions=['maximize', 'maximize'])\n",
    "# # study = optuna.create_study(directions=['maximize'])\n",
    "\n",
    "# # Execute optimization\n",
    "# study.optimize(multi_objective_trial, n_trials=3)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trials:\")\n",
    "# for trial in study.best_trials:\n",
    "#     print(f\"  Win Rate: {trial.values[0]}\")\n",
    "#     print(f\"  Average Tries Remaining: {trial.values[1]}\")\n",
    "#     print(f\"  Thresholds: {trial.params}\")\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.api import HangmanAPI\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the file\n",
    "file_path = '/media/sayem/510B93E12554BBD1/Hangman/notebooks/api_key.txt'\n",
    "\n",
    "# Use a context manager to open and read the file\n",
    "with open(file_path, 'r') as file:\n",
    "    api_key = file.read().strip()  # Read the content and strip any extra whitespace\n",
    "\n",
    "# print(\"API Key:\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HangmanAPI(model=model, corpus_path=corpus_path, \\\n",
    "                solver=solver, transform=transform, \\\n",
    "                access_token=api_key, process_word_fn=process_word, timeout=2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.start_game(practice=1, verbose=True)\n",
    "[total_practice_runs, total_recorded_runs,total_recorded_successes, total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "practice_success_rate = total_practice_successes / total_practice_runs\n",
    "print('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs, total_recorded_runs, \\\n",
    "            total_recorded_successes, total_practice_successes] = api.my_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs, total_recorded_runs, total_recorded_successes, total_practice_successes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print('Playing ', i, ' th game')\n",
    "    # Uncomment the following line to execute your final runs. Do not do this until you are satisfied with your submission\n",
    "    # api.start_game(practice=0,verbose=False)\n",
    "    api.start_game(practice=1, verbose=False)\n",
    "    # DO NOT REMOVE as otherwise the server may lock you out for too high frequency of requests\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs,total_recorded_runs,total_recorded_successes,total_practice_successes] = api.my_status() # Get my game stats: (# of tries, # of wins)\n",
    "practice_success_rate = total_practice_successes / total_practice_runs\n",
    "print('run %d practice games out of an allotted 100,000. practice success rate so far = %.3f' % (total_practice_runs, practice_success_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[total_practice_runs, total_recorded_runs, total_recorded_successes, total_practice_successes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
